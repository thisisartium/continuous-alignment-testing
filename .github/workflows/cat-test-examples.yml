name: CAT

on:
  push:
    branches: [ ci-experiment/** ]
  workflow_dispatch:
    inputs:
      rounds:
        description: "Number of Rounds 1 - 128"
        type: number
        required: true
        default: 10

jobs:
  ai_tests:
    name: AI Tests
    runs-on: ubuntu-latest
    env:
      TEST_RESULTS_FOLDER: examples/team_recommender/test_runs
      PYTHONUNBUFFERED: 1

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          prune-cache: false

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"

      - name: Install the project
        run: uv sync --all-extras --dev

      - name: Check if GOOGLE_CREDENTIALS is set
        run: |
          if [ -z "${{ secrets.GOOGLE_CREDENTIALS }}" ]; then
            echo "Error: GOOGLE_CREDENTIALS secret is not set!"
            exit 1
          fi

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GOOGLE_CREDENTIALS }}'

      - name: Set number of runs
        id: set-number-of-runs
        env:
          INPUTS_ROUNDS_OR_EMPTY: ${{ inputs.rounds }}
        run: |
          [[ "${GITHUB_REF_NAME}" =~ ^ci-experiment/ ]] && ROUNDS=1 || ROUNDS=10
          ROUNDS=${INPUTS_ROUNDS_OR_EMPTY:-$ROUNDS}
          
          if [ "$ROUNDS" -gt 128 ] || [ "$ROUNDS" -le 0 ]
          then
            echo "Invalid number of rounds: $ROUNDS"
            exit 1
          fi

          echo "::notice::Starting ${ROUNDS} run$([ "$ROUNDS" -eq 1 ] || echo "s")"
          echo "number_of_runs=$ROUNDS" >> "$GITHUB_OUTPUT"
          echo "CAT_AI_SAMPLE_SIZE=$ROUNDS" >> $GITHUB_ENV

      - name: Find latest example
        uses: mathiasvr/command-output@v2.0.0
        id: find-latest-example
        with:
          run: find examples/team_recommender/tests -maxdepth 1 -name "example_*" -type d | sort -V | tail -n 1

      - name: Run Latest Example tests
        run: >
          uv run pytest
          --verbose --verbosity=10 --capture=no --tb=native --color=yes --showlocals
          ${{ steps.find-latest-example.outputs.stdout }}
        # examples/team_recommender/tests/example_9*
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

#      - name: Upload artifacts to MinIO
#        run: |
#          zip -r test-output-${{ github.run_number }}.zip "examples/team_recommender/test_runs"
#            curl -X PUT -T "/path/to/yourfile.zip" \
#            -H "Host: localhost:9000" \
#            -H "Date: $(date -R)" \
#            -H "Content-Type: application/zip" \
#            -H "Authorization: AWS minioadmin:minioadmin" \
#            http://localhost:9000/yourbucket/yourfile.zip

      - name: Show CAT AI Statistical Report
        if: always()
        run: |          
          FAILURE_COUNT=$(find "$TEST_RESULTS_FOLDER" -type f -name "fail-*.json" | wc -l)
          PYTHONPATH=src uv run python -m cat_ai.reporter \
            "$FAILURE_COUNT" \
            "$CAT_AI_SAMPLE_SIZE" \
            >> "$GITHUB_STEP_SUMMARY"

      - name: Upload main artifacts to Google Drive
        if: always() && github.ref_name == 'main'
        run: |
          zip -r "$ZIP_WITH_RUN" "$TEST_RESULTS_FOLDER"
          uv run python src/cat_ai/publish_to_gdrive.py "$ZIP_WITH_RUN"
        env:
          PARENT_FOLDER_IDS: ${{ vars.GOOGLE_DRIVE_TEST_OUTPUT_FOLDER_ID }}
          ZIP_WITH_RUN: test-output-${{ github.run_number }}.zip

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
            name: test-output-${{ github.run_number }}
            path: ${{ env.TEST_RESULTS_FOLDER }}

      - name: Debugging with tmate
        if: failure()
        uses: lhotari/action-upterm@v1
        with:
          wait-timeout-minutes: 5
